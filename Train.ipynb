{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Convolution2D,MaxPooling2D,Dropout,Dense,Flatten, GlobalAveragePooling2D\n",
    "from keras import models,losses,optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import InceptionV3,VGG16\n",
    "from keras.models import Model\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('dataset/train/A/001.jpg')\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.imshow('this',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for layer in base_model.layers:\\n        layer.trainable = False'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for l in model2.layers[:249]:\n",
    "    l.trainable = False\n",
    "for l in model2.layers[249:]:\n",
    "    l.trainable = True\n",
    "    \n",
    "'''for layer in base_model.layers:\n",
    "        layer.trainable = False'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for l in model2.layers[:249]:\n",
    "    l.trainable = False\n",
    "for l in model2.layers[249:]:\n",
    "    l.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 3 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 3 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 3 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 3 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, None, 3 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 6 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 6 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, None, 6 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 6 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 8 5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 8 240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, None, 8 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 1 138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 1 576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 1 0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 6 192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, None, 6 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 4 9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 9 55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 4 144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 9 288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, None, 4 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, None, 9 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, None, None, 1 0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 6 76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 9 82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 3 6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 6 192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 6 192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 9 288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 3 96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, None, 6 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, None, 9 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, None, 3 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, None, None, 2 0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, None, 6 192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, None, 6 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 4 12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 9 55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, None, 4 144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, None, 9 288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, None, 4 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, None, None, 9 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, None, None, 2 0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 6 76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 9 82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 6 16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, None, 6 192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, None, 6 192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, None, 9 288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, None, 6 192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, None, 6 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, None, 6 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, None, None, 9 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, None, None, 6 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, None, None, 2 0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, None, 6 192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, None, None, 6 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 4 13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 9 55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, None, 4 144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, None, 9 288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, None, None, 4 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, None, None, 9 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, None, None, 2 0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 6 76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 9 82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 6 18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, None, 6 192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, None, 6 192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, None, 9 288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, None, 6 192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, None, None, 6 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, None, None, 6 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, None, None, 9 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, None, None, 6 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, None, None, 2 0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 6 18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, None, None, 6 192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, None, None, 6 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, None, None, 9 55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, None, None, 9 288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, None, None, 9 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 3 995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, None, None, 9 82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, None, 3 1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, None, 9 288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, None, None, 3 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, None, None, 9 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 2 0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, None, None, 7 0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, None, None, 1 384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, None, None, 1 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, None, None, 1 114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, None, None, 1 384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, None, None, 1 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, None, None, 1 114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, None, 1 384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, None, None, 1 384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, None, None, 1 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, None, None, 1 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, None, None, 1 114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, None, None, 1 114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, None, 1 384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, None, None, 1 384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, None, None, 1 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, None, None, 1 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, None, None, 7 0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, None, None, 1 147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, None, None, 1 172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, None, None, 1 172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, None, 1 576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, None, None, 1 576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, None, None, 1 576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, None, None, 1 576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, None, None, 1 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, None, None, 1 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, None, None, 1 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, None, None, 1 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, None, None, 7 0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, None, None, 1 480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, None, None, 1 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, None, None, 1 179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, None, None, 1 480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, None, None, 1 0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, None, None, 1 179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, None, None, 1 480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, None, None, 1 480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, None, None, 1 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, None, None, 1 0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, None, None, 1 179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, None, None, 1 179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, None, None, 1 480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, None, None, 1 480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, None, None, 1 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, None, None, 1 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, None, None, 7 0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, None, None, 1 147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, None, None, 1 215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, None, None, 1 215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, None, None, 1 576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, None, None, 1 576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, None, None, 1 576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, None, None, 1 576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, None, None, 1 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, None, None, 1 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, None, 1 0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, None, None, 1 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, None, None, 7 0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, None, None, 1 480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, None, None, 1 0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, None, None, 1 179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, None, None, 1 480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, None, None, 1 0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, None, None, 1 179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, None, None, 1 480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, None, None, 1 480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, None, None, 1 0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, None, None, 1 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, None, None, 1 179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, None, None, 1 179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, None, None, 1 480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, None, None, 1 480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, None, None, 1 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, None, None, 1 0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, None, None, 7 0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, None, None, 1 147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, None, None, 1 215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, None, None, 1 215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, None, None, 1 576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, None, None, 1 576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, None, None, 1 576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, None, None, 1 576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, None, None, 1 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, None, None, 1 0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, None, None, 1 0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, None, None, 1 0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, None, None, 7 0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, None, None, 1 576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, None, None, 1 0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, None, None, 1 258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, None, None, 1 576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, None, None, 1 0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, None, None, 1 258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, None, None, 1 576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, None, None, 1 576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, None, None, 1 0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, None, None, 1 0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, None, None, 1 258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, None, None, 1 258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, None, None, 1 576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, None, None, 1 576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, None, None, 1 0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, None, None, 1 0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, None, None, 7 0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, None, None, 1 258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, None, None, 1 258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, None, None, 1 576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, None, None, 1 576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, None, None, 1 576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, None, None, 1 576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, None, None, 1 0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, None, None, 1 0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, None, None, 1 0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, None, None, 1 0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, None, None, 7 0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, None, None, 1 576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, None, None, 1 0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, None, None, 1 258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, None, None, 1 576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, None, None, 1 0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, None, None, 1 258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, None, None, 1 576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, None, None, 1 576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, None, None, 1 0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, None, None, 1 0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, None, None, 3 552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, None, None, 1 331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, None, None, 3 960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, None, None, 1 576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, None, None, 3 0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, None, None, 1 0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, None, None, 7 0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, None, None, 1 0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, None, None, 4 573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, None, None, 4 1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, None, None, 4 0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, None, None, 3 491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, None, None, 3 1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, None, None, 3 1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, None, None, 3 1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, None, None, 3 0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, None, None, 3 0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, None, None, 1 0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, None, None, 3 409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, None, None, 3 1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, None, None, 3 1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, None, None, 3 1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, None, None, 3 1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, None, None, 1 245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, None, None, 3 960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, None, None, 3 0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, None, None, 3 0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, None, None, 3 0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, None, None, 3 0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, None, None, 1 576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, None, None, 3 0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 7 0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, None, None, 1 0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, None, None, 2 0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, None, None, 4 917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, None, None, 4 1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, None, None, 4 0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, None, None, 3 786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, None, None, 3 1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, None, None, 3 1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, None, None, 3 1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, None, None, 3 0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, None, None, 3 0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, None, None, 2 0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, None, None, 3 655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, None, None, 3 1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, None, None, 3 1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, None, None, 3 1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, None, None, 3 1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, None, None, 1 393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, None, None, 3 960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, None, None, 3 0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, None, None, 3 0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, None, None, 3 0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, None, None, 3 0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, None, None, 1 576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, None, None, 3 0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, None, None, 7 0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, None, None, 1 0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, None, None, 2 0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         2098176     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 24)           24600       dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,925,560\n",
      "Trainable params: 13,237,656\n",
      "Non-trainable params: 10,687,904\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = models.Sequential()\n",
    "model1.add(layer=Convolution2D(filters=32,kernel_size=(5,5),strides=(1,1),activation='relu',input_shape= (32,32,3)))\n",
    "model1.add(layer = MaxPooling2D(strides=(2,2)))\n",
    "model1.add(layer=Convolution2D(filters=64,kernel_size=(5,5),strides=(1,1),activation='relu'))\n",
    "model1.add(layer = MaxPooling2D(strides=(2,2)))\n",
    "#Flattening the pooled layer\n",
    "model1.add(layer= Flatten())\n",
    "#Creating the ANN\n",
    "model1.add(layer = Dense(units = 1024, activation= 'relu'))\n",
    "model1.add(layer = Dropout(0.5))\n",
    "model1.add(layer = Dense(units = 24, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_383 (Conv2D)          (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_384 (Conv2D)          (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 124)               777852    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 124)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 24)                3000      \n",
      "=================================================================\n",
      "Total params: 790,996\n",
      "Trainable params: 790,996\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optim = optimizers.adam(lr=0.001)\n",
    "model1.compile(optimizer= optim,loss = losses.categorical_crossentropy,metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4972 images belonging to 24 classes.\n",
      "Found 443 images belonging to 24 classes.\n"
     ]
    }
   ],
   "source": [
    "def transform(image):\n",
    "    return cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",

    "train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=20,shear_range=0.2,zoom_range=0.2,horizontal_flip=True,vertical_flip=True,preprocessing_function=transform)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255,preprocessing_function=transform)\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('dataset/train/',target_size=(32, 32),batch_size=10,class_mode=\"categorical\",color_mode='rgb',shuffle= True)\n",
    "test_set = test_datagen.flow_from_directory('dataset/test',target_size=(32, 32),batch_size=1,class_mode=\"categorical\",color_mode='rgb',shuffle= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "497/497 [==============================] - 329s 661ms/step - loss: 2.2247 - acc: 0.3101 - val_loss: 1.1218 - val_acc: 0.6411\n",
      "Epoch 2/5\n",
      "497/497 [==============================] - 177s 355ms/step - loss: 1.2462 - acc: 0.5913 - val_loss: 0.5973 - val_acc: 0.8104\n",
      "Epoch 3/5\n",
      "497/497 [==============================] - 177s 356ms/step - loss: 0.8719 - acc: 0.7161 - val_loss: 0.4350 - val_acc: 0.8510\n",
      "Epoch 4/5\n",
      "497/497 [==============================] - 179s 359ms/step - loss: 0.6959 - acc: 0.7712 - val_loss: 0.5025 - val_acc: 0.8465\n",
      "Epoch 5/5\n",
      "497/497 [==============================] - 177s 357ms/step - loss: 0.5868 - acc: 0.8016 - val_loss: 0.2775 - val_acc: 0.9029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2564dfc39e8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit_generator(train_set,steps_per_epoch=497,epochs=5,validation_data=test_set,validation_steps=443)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_mod = model1.to_json()\n",
    "with open('model1_manualCNN.json','w') as file:\n",
    "    file.write(json_mod)\n",
    "model1.save_weights('model1_manualCNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# VGG16 network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Convolution2D,MaxPooling2D,Dropout,Dense,Flatten, GlobalAveragePooling2D\n",
    "from keras import models,losses,optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import InceptionV3,VGG16\n",
    "from keras.models import Model\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prior = VGG16(\n",
    "    include_top=False, \n",
    "    weights='imagenet',\n",
    "    input_shape=(48, 48, 3)\n",
    ")\n",
    "model3 = models.Sequential()\n",
    "model3.add(prior)\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(256, activation='relu', name='Dense_Intermediate'))\n",
    "model3.add(Dropout(0.1, name='Dropout_Regularization'))\n",
    "model3.add(Dense(24, activation='sigmoid', name='Output'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for cnn_block_layer in model3.layers[0].layers:\n",
    "    cnn_block_layer.trainable = False\n",
    "model3.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4972 images belonging to 24 classes.\n",
      "Found 443 images belonging to 24 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=20,shear_range=0.2,zoom_range=0.2,horizontal_flip=True,vertical_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('dataset/train/',target_size=(48, 48),batch_size=10,class_mode=\"categorical\",color_mode='rgb',shuffle= True)\n",
    "test_set = test_datagen.flow_from_directory('dataset/test',target_size=(48, 48),batch_size=1,class_mode=\"categorical\",color_mode='rgb',shuffle= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "labels_count = dict()\n",
    "for img_class in [ic for ic in os.listdir('dataset/train/') if ic[0] != '.']:\n",
    "    labels_count[img_class] = len(os.listdir('dataset/train/' + img_class))\n",
    "total_count = sum(labels_count.values())\n",
    "class_weights = {cls: total_count / count for cls, count in \n",
    "                 enumerate(labels_count.values())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "497/497 [==============================] - 232s 467ms/step - loss: 12.5241 - acc: 0.8205 - val_loss: 0.2691 - val_acc: 0.8894\n",
      "Epoch 2/10\n",
      "497/497 [==============================] - 235s 473ms/step - loss: 11.3296 - acc: 0.8396 - val_loss: 0.3354 - val_acc: 0.8781\n",
      "Epoch 3/10\n",
      "497/497 [==============================] - 242s 486ms/step - loss: 10.6019 - acc: 0.8515 - val_loss: 0.3123 - val_acc: 0.8871\n",
      "Epoch 4/10\n",
      "497/497 [==============================] - 234s 470ms/step - loss: 10.6684 - acc: 0.8521 - val_loss: 0.2008 - val_acc: 0.9187\n",
      "Epoch 5/10\n",
      "497/497 [==============================] - 235s 473ms/step - loss: 9.8157 - acc: 0.8551 - val_loss: 0.2371 - val_acc: 0.8962\n",
      "Epoch 6/10\n",
      "497/497 [==============================] - 234s 470ms/step - loss: 9.4443 - acc: 0.8666 - val_loss: 0.1712 - val_acc: 0.9142\n",
      "Epoch 7/10\n",
      "497/497 [==============================] - 231s 464ms/step - loss: 9.4843 - acc: 0.8626 - val_loss: 0.2427 - val_acc: 0.9097\n",
      "Epoch 8/10\n",
      "497/497 [==============================] - 232s 468ms/step - loss: 9.1189 - acc: 0.8726 - val_loss: 0.1448 - val_acc: 0.9594\n",
      "Epoch 9/10\n",
      "497/497 [==============================] - 232s 466ms/step - loss: 8.5614 - acc: 0.8718 - val_loss: 0.2001 - val_acc: 0.9368\n",
      "Epoch 10/10\n",
      "497/497 [==============================] - 233s 469ms/step - loss: 8.3346 - acc: 0.8809 - val_loss: 0.1920 - val_acc: 0.9300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25600270438>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit_generator(\n",
    "    train_set,\n",
    "    steps_per_epoch=len(train_set.filenames) // 10,\n",
    "    epochs=10,\n",
    "    validation_data=test_set,\n",
    "    validation_steps=len(test_set.filenames) // 1,\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_mod = model3.to_json()\n",
    "#Fine tuning of the model\n",
    "with open('model3_VGG16.json','w') as file:\n",
    "    file.write(json_mod)\n",
    "model3.save_weights('model3_VGG16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 1, 1, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "Dense_Intermediate (Dense)   (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "Dropout_Regularization (Drop (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 24)                6168      \n",
      "=================================================================\n",
      "Total params: 14,852,184\n",
      "Trainable params: 137,496\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 48, 48, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 48, 48, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 48, 48, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "prior.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x0000025650896780> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000025650896C50> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000025650896F60> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x00000256508D5400> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000256508D5278> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000256508EE630> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x00000256509081D0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000025650908CF8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000002565093E1D0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000256509554A8> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x0000025650970400> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000025650970CF8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000256509A71D0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000256509BF4A8> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x00000256509D9400> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000256509D9CF8> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000025650A101D0> True\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000025650A274A8> True\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x0000025650A41400> True\n"
     ]
    }
   ],
   "source": [
    "for layer in prior.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "for layer in prior.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "# Check the trainable status of the individual layers\n",
    "for layer in prior.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 16/497 [..............................] - ETA: 4:08 - loss: 123.3966 - acc: 0.4438"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-269-01146773761d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model3.fit_generator(\n",
    "    train_set,\n",
    "    steps_per_epoch=len(train_set.filenames) // 50,\n",
    "    epochs=50,\n",
    "    validation_data=test_set,\n",
    "    validation_steps=len(test_set.filenames) // 1,\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception v3 Fine tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial, update_wrapper\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "from keras.callbacks import ModelCheckpoint,TensorBoard\n",
    "from keras import backend as K\n",
    "import os.path\n",
    "import fnmatch\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4972 images belonging to 24 classes.\n",
      "Found 443 images belonging to 24 classes.\n"
     ]
    }
   ],
   "source": [
    "def transform(image):\n",
    "    return cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=20,shear_range=0.2,zoom_range=0.2,horizontal_flip=True,vertical_flip=True,preprocessing_function=transform)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255,preprocessing_function=transform)\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('dataset/train/',target_size=(64, 64),batch_size=10,class_mode=\"categorical\",color_mode='rgb',shuffle= True)\n",
    "test_set = test_datagen.flow_from_directory('dataset/test/',target_size=(64, 64),batch_size=1,class_mode=\"categorical\",color_mode='rgb',shuffle= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_layers_checkpoint_path = 'cp.top.best.hdf5'\n",
    "fine_tuned_checkpoint_path = 'cp.fine_tuned.best.hdf5'\n",
    "new_extended_inception_weights = 'final_weights.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def w_categorical_crossentropy(y_true, y_pred, weights):\n",
    "    nb_cl = len(weights)\n",
    "    final_mask = K.zeros_like(y_pred[:, 0])\n",
    "    y_pred_max = K.max(y_pred, axis=1)\n",
    "    y_pred_max = K.expand_dims(y_pred_max, 1)\n",
    "    y_pred_max_mat = K.equal(y_pred, y_pred_max)\n",
    "    for c_p, c_t in itertools.product(range(nb_cl), range(nb_cl)):\n",
    "        final_mask += (K.cast(weights[c_t, c_p],K.floatx()) * K.cast(y_pred_max_mat[:, c_p] ,K.floatx())* K.cast(y_true[:, c_t],K.floatx()))\n",
    "    return K.categorical_crossentropy(y_pred, y_true) * final_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wrapped_partial(func, *args, **kwargs):\n",
    "    partial_func = partial(func, *args, **kwargs)\n",
    "    update_wrapper(partial_func, func)\n",
    "    return partial_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_array = np.ones((2,2))\n",
    "w_array[1,0] = 1.2\n",
    "ncce = wrapped_partial(w_categorical_crossentropy, weights=w_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "base_model = InceptionV3(weights = 'imagenet', include_top = False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024,activation = 'relu')(x)\n",
    "predictions = Dense(24,activation = 'softmax')(x)\n",
    "model2 = Model(inputs = base_model.input, output = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2.compile(optimizer='rmsprop', loss=ncce, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save the model after every epoch.\n",
    "mc_top = ModelCheckpoint(top_layers_checkpoint_path, monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "#Save the TensorBoard logs. histogram_freq was 1 (gave errors) and now is 0. write_images was True (read that this is heavy) and now is False\n",
    "tb = TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=False, write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "labels_count = dict()\n",
    "for img_class in [ic for ic in os.listdir('dataset/train/') if ic[0] != '.']:\n",
    "    labels_count[img_class] = len(os.listdir('dataset/train/' + img_class))\n",
    "total_count = sum(labels_count.values())\n",
    "class_weights = {cls: total_count / count for cls, count in \n",
    "                 enumerate(labels_count.values())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 56/497 [==>...........................] - ETA: 4:42 - loss: nan - acc: 0.0500"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-8d27424e9d6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmc_top\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m                 \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    683\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model2.fit_generator(train_set,steps_per_epoch=len(train_set.filenames) // 10,epochs=10,validation_data=test_set,validation_steps=len(test_set.filenames) // 10,callbacks=[mc_top, tb],class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 conv2d_1\n",
      "2 batch_normalization_1\n",
      "3 activation_1\n",
      "4 conv2d_2\n",
      "5 batch_normalization_2\n",
      "6 activation_2\n",
      "7 conv2d_3\n",
      "8 batch_normalization_3\n",
      "9 activation_3\n",
      "10 max_pooling2d_1\n",
      "11 conv2d_4\n",
      "12 batch_normalization_4\n",
      "13 activation_4\n",
      "14 conv2d_5\n",
      "15 batch_normalization_5\n",
      "16 activation_5\n",
      "17 max_pooling2d_2\n",
      "18 conv2d_9\n",
      "19 batch_normalization_9\n",
      "20 activation_9\n",
      "21 conv2d_7\n",
      "22 conv2d_10\n",
      "23 batch_normalization_7\n",
      "24 batch_normalization_10\n",
      "25 activation_7\n",
      "26 activation_10\n",
      "27 average_pooling2d_1\n",
      "28 conv2d_6\n",
      "29 conv2d_8\n",
      "30 conv2d_11\n",
      "31 conv2d_12\n",
      "32 batch_normalization_6\n",
      "33 batch_normalization_8\n",
      "34 batch_normalization_11\n",
      "35 batch_normalization_12\n",
      "36 activation_6\n",
      "37 activation_8\n",
      "38 activation_11\n",
      "39 activation_12\n",
      "40 mixed0\n",
      "41 conv2d_16\n",
      "42 batch_normalization_16\n",
      "43 activation_16\n",
      "44 conv2d_14\n",
      "45 conv2d_17\n",
      "46 batch_normalization_14\n",
      "47 batch_normalization_17\n",
      "48 activation_14\n",
      "49 activation_17\n",
      "50 average_pooling2d_2\n",
      "51 conv2d_13\n",
      "52 conv2d_15\n",
      "53 conv2d_18\n",
      "54 conv2d_19\n",
      "55 batch_normalization_13\n",
      "56 batch_normalization_15\n",
      "57 batch_normalization_18\n",
      "58 batch_normalization_19\n",
      "59 activation_13\n",
      "60 activation_15\n",
      "61 activation_18\n",
      "62 activation_19\n",
      "63 mixed1\n",
      "64 conv2d_23\n",
      "65 batch_normalization_23\n",
      "66 activation_23\n",
      "67 conv2d_21\n",
      "68 conv2d_24\n",
      "69 batch_normalization_21\n",
      "70 batch_normalization_24\n",
      "71 activation_21\n",
      "72 activation_24\n",
      "73 average_pooling2d_3\n",
      "74 conv2d_20\n",
      "75 conv2d_22\n",
      "76 conv2d_25\n",
      "77 conv2d_26\n",
      "78 batch_normalization_20\n",
      "79 batch_normalization_22\n",
      "80 batch_normalization_25\n",
      "81 batch_normalization_26\n",
      "82 activation_20\n",
      "83 activation_22\n",
      "84 activation_25\n",
      "85 activation_26\n",
      "86 mixed2\n",
      "87 conv2d_28\n",
      "88 batch_normalization_28\n",
      "89 activation_28\n",
      "90 conv2d_29\n",
      "91 batch_normalization_29\n",
      "92 activation_29\n",
      "93 conv2d_27\n",
      "94 conv2d_30\n",
      "95 batch_normalization_27\n",
      "96 batch_normalization_30\n",
      "97 activation_27\n",
      "98 activation_30\n",
      "99 max_pooling2d_3\n",
      "100 mixed3\n",
      "101 conv2d_35\n",
      "102 batch_normalization_35\n",
      "103 activation_35\n",
      "104 conv2d_36\n",
      "105 batch_normalization_36\n",
      "106 activation_36\n",
      "107 conv2d_32\n",
      "108 conv2d_37\n",
      "109 batch_normalization_32\n",
      "110 batch_normalization_37\n",
      "111 activation_32\n",
      "112 activation_37\n",
      "113 conv2d_33\n",
      "114 conv2d_38\n",
      "115 batch_normalization_33\n",
      "116 batch_normalization_38\n",
      "117 activation_33\n",
      "118 activation_38\n",
      "119 average_pooling2d_4\n",
      "120 conv2d_31\n",
      "121 conv2d_34\n",
      "122 conv2d_39\n",
      "123 conv2d_40\n",
      "124 batch_normalization_31\n",
      "125 batch_normalization_34\n",
      "126 batch_normalization_39\n",
      "127 batch_normalization_40\n",
      "128 activation_31\n",
      "129 activation_34\n",
      "130 activation_39\n",
      "131 activation_40\n",
      "132 mixed4\n",
      "133 conv2d_45\n",
      "134 batch_normalization_45\n",
      "135 activation_45\n",
      "136 conv2d_46\n",
      "137 batch_normalization_46\n",
      "138 activation_46\n",
      "139 conv2d_42\n",
      "140 conv2d_47\n",
      "141 batch_normalization_42\n",
      "142 batch_normalization_47\n",
      "143 activation_42\n",
      "144 activation_47\n",
      "145 conv2d_43\n",
      "146 conv2d_48\n",
      "147 batch_normalization_43\n",
      "148 batch_normalization_48\n",
      "149 activation_43\n",
      "150 activation_48\n",
      "151 average_pooling2d_5\n",
      "152 conv2d_41\n",
      "153 conv2d_44\n",
      "154 conv2d_49\n",
      "155 conv2d_50\n",
      "156 batch_normalization_41\n",
      "157 batch_normalization_44\n",
      "158 batch_normalization_49\n",
      "159 batch_normalization_50\n",
      "160 activation_41\n",
      "161 activation_44\n",
      "162 activation_49\n",
      "163 activation_50\n",
      "164 mixed5\n",
      "165 conv2d_55\n",
      "166 batch_normalization_55\n",
      "167 activation_55\n",
      "168 conv2d_56\n",
      "169 batch_normalization_56\n",
      "170 activation_56\n",
      "171 conv2d_52\n",
      "172 conv2d_57\n",
      "173 batch_normalization_52\n",
      "174 batch_normalization_57\n",
      "175 activation_52\n",
      "176 activation_57\n",
      "177 conv2d_53\n",
      "178 conv2d_58\n",
      "179 batch_normalization_53\n",
      "180 batch_normalization_58\n",
      "181 activation_53\n",
      "182 activation_58\n",
      "183 average_pooling2d_6\n",
      "184 conv2d_51\n",
      "185 conv2d_54\n",
      "186 conv2d_59\n",
      "187 conv2d_60\n",
      "188 batch_normalization_51\n",
      "189 batch_normalization_54\n",
      "190 batch_normalization_59\n",
      "191 batch_normalization_60\n",
      "192 activation_51\n",
      "193 activation_54\n",
      "194 activation_59\n",
      "195 activation_60\n",
      "196 mixed6\n",
      "197 conv2d_65\n",
      "198 batch_normalization_65\n",
      "199 activation_65\n",
      "200 conv2d_66\n",
      "201 batch_normalization_66\n",
      "202 activation_66\n",
      "203 conv2d_62\n",
      "204 conv2d_67\n",
      "205 batch_normalization_62\n",
      "206 batch_normalization_67\n",
      "207 activation_62\n",
      "208 activation_67\n",
      "209 conv2d_63\n",
      "210 conv2d_68\n",
      "211 batch_normalization_63\n",
      "212 batch_normalization_68\n",
      "213 activation_63\n",
      "214 activation_68\n",
      "215 average_pooling2d_7\n",
      "216 conv2d_61\n",
      "217 conv2d_64\n",
      "218 conv2d_69\n",
      "219 conv2d_70\n",
      "220 batch_normalization_61\n",
      "221 batch_normalization_64\n",
      "222 batch_normalization_69\n",
      "223 batch_normalization_70\n",
      "224 activation_61\n",
      "225 activation_64\n",
      "226 activation_69\n",
      "227 activation_70\n",
      "228 mixed7\n",
      "229 conv2d_73\n",
      "230 batch_normalization_73\n",
      "231 activation_73\n",
      "232 conv2d_74\n",
      "233 batch_normalization_74\n",
      "234 activation_74\n",
      "235 conv2d_71\n",
      "236 conv2d_75\n",
      "237 batch_normalization_71\n",
      "238 batch_normalization_75\n",
      "239 activation_71\n",
      "240 activation_75\n",
      "241 conv2d_72\n",
      "242 conv2d_76\n",
      "243 batch_normalization_72\n",
      "244 batch_normalization_76\n",
      "245 activation_72\n",
      "246 activation_76\n",
      "247 max_pooling2d_4\n",
      "248 mixed8\n",
      "249 conv2d_81\n",
      "250 batch_normalization_81\n",
      "251 activation_81\n",
      "252 conv2d_78\n",
      "253 conv2d_82\n",
      "254 batch_normalization_78\n",
      "255 batch_normalization_82\n",
      "256 activation_78\n",
      "257 activation_82\n",
      "258 conv2d_79\n",
      "259 conv2d_80\n",
      "260 conv2d_83\n",
      "261 conv2d_84\n",
      "262 average_pooling2d_8\n",
      "263 conv2d_77\n",
      "264 batch_normalization_79\n",
      "265 batch_normalization_80\n",
      "266 batch_normalization_83\n",
      "267 batch_normalization_84\n",
      "268 conv2d_85\n",
      "269 batch_normalization_77\n",
      "270 activation_79\n",
      "271 activation_80\n",
      "272 activation_83\n",
      "273 activation_84\n",
      "274 batch_normalization_85\n",
      "275 activation_77\n",
      "276 mixed9_0\n",
      "277 concatenate_1\n",
      "278 activation_85\n",
      "279 mixed9\n",
      "280 conv2d_90\n",
      "281 batch_normalization_90\n",
      "282 activation_90\n",
      "283 conv2d_87\n",
      "284 conv2d_91\n",
      "285 batch_normalization_87\n",
      "286 batch_normalization_91\n",
      "287 activation_87\n",
      "288 activation_91\n",
      "289 conv2d_88\n",
      "290 conv2d_89\n",
      "291 conv2d_92\n",
      "292 conv2d_93\n",
      "293 average_pooling2d_9\n",
      "294 conv2d_86\n",
      "295 batch_normalization_88\n",
      "296 batch_normalization_89\n",
      "297 batch_normalization_92\n",
      "298 batch_normalization_93\n",
      "299 conv2d_94\n",
      "300 batch_normalization_86\n",
      "301 activation_88\n",
      "302 activation_89\n",
      "303 activation_92\n",
      "304 activation_93\n",
      "305 batch_normalization_94\n",
      "306 activation_86\n",
      "307 mixed9_1\n",
      "308 concatenate_2\n",
      "309 activation_94\n",
      "310 mixed10\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mc_fit = ModelCheckpoint(fine_tuned_checkpoint_path, monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if os.path.exists(fine_tuned_checkpoint_path):\n",
    "    model1.load_weights(fine_tuned_checkpoint_path)\n",
    "    print (\"Checkpoint '\" + fine_tuned_checkpoint_path + \"' loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "# in other examples found it was 172 insted 249. \n",
    "# I took 249 according to https://keras.io/applications/#inceptionv3\n",
    "for layer in model2.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in model2.layers[249:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "model2.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss=ncce, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "113/113 [==============================] - 71s 627ms/step - loss: nan - acc: 0.2002 - val_loss: nan - val_acc: 0.1895\n",
      "Epoch 2/50\n",
      "113/113 [==============================] - 64s 566ms/step - loss: nan - acc: 0.2254 - val_loss: nan - val_acc: 0.1895\n",
      "Epoch 3/50\n",
      " 50/113 [============>.................] - ETA: 30s - loss: nan - acc: 0.2020"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-724132ee22e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m113\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m95\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmc_fit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m                 \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    683\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model2.fit_generator(train_set,steps_per_epoch=len(train_set.filenames) // 10,epochs=50,validation_data=test_set,validation_steps=len(test_set.filenames) // 10,callbacks=[mc_fit, tb],class_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4972 images belonging to 24 classes.\n",
      "Found 443 images belonging to 24 classes.\n"
     ]
    }
   ],
   "source": [
    "def transform(image):\n",
    "    return cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=0,shear_range=0.0,zoom_range=0.0,horizontal_flip=True,vertical_flip=True,preprocessing_function=transform)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255,preprocessing_function=transform)\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('dataset/train/',target_size=(48, 48),batch_size=10,class_mode=\"categorical\",color_mode='rgb',shuffle= True)\n",
    "test_set = test_datagen.flow_from_directory('dataset/test',target_size=(48, 48),batch_size=1,class_mode=\"categorical\",color_mode='rgb',shuffle= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJc1+J8cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(next(train_set)[0][0][:,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBULDJ6RAaPiEFMj/B3xWDbayFQKaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = cv2.resize(transform(cv2.imread('dataset/train/H/005.jpg')),(48,48))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphabets = ('a','b','c','d','e','f','g','h','i','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "test_image = image.load_img('dataset/train/L/001.jpg', target_size = (48, 48),grayscale=False)\n",
    "#test_image = image.load_img('dataset/test_vague/Q_test.jpg', target_size = (128, 128),grayscale=False)\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = cv2.cvtColor(test_image,cv2.COLOR_BGR2)\n",
    "test_image = test_image/255\n",
    "test_image = np.expand_dims(test_image, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'l'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(test_image[0][:,:,:])\n",
    "plt.show()\n",
    "alphabets[np.argmax(model3.predict(test_image))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "next(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Colormap color is not recognized. Possible values are: Accent, Accent_r, Blues, Blues_r, BrBG, BrBG_r, BuGn, BuGn_r, BuPu, BuPu_r, CMRmap, CMRmap_r, Dark2, Dark2_r, GnBu, GnBu_r, Greens, Greens_r, Greys, Greys_r, OrRd, OrRd_r, Oranges, Oranges_r, PRGn, PRGn_r, Paired, Paired_r, Pastel1, Pastel1_r, Pastel2, Pastel2_r, PiYG, PiYG_r, PuBu, PuBuGn, PuBuGn_r, PuBu_r, PuOr, PuOr_r, PuRd, PuRd_r, Purples, Purples_r, RdBu, RdBu_r, RdGy, RdGy_r, RdPu, RdPu_r, RdYlBu, RdYlBu_r, RdYlGn, RdYlGn_r, Reds, Reds_r, Set1, Set1_r, Set2, Set2_r, Set3, Set3_r, Spectral, Spectral_r, Wistia, Wistia_r, YlGn, YlGnBu, YlGnBu_r, YlGn_r, YlOrBr, YlOrBr_r, YlOrRd, YlOrRd_r, afmhot, afmhot_r, autumn, autumn_r, binary, binary_r, bone, bone_r, brg, brg_r, bwr, bwr_r, cividis, cividis_r, cool, cool_r, coolwarm, coolwarm_r, copper, copper_r, cubehelix, cubehelix_r, flag, flag_r, gist_earth, gist_earth_r, gist_gray, gist_gray_r, gist_heat, gist_heat_r, gist_ncar, gist_ncar_r, gist_rainbow, gist_rainbow_r, gist_stern, gist_stern_r, gist_yarg, gist_yarg_r, gnuplot, gnuplot2, gnuplot2_r, gnuplot_r, gray, gray_r, hot, hot_r, hsv, hsv_r, inferno, inferno_r, jet, jet_r, magma, magma_r, nipy_spectral, nipy_spectral_r, ocean, ocean_r, pink, pink_r, plasma, plasma_r, prism, prism_r, rainbow, rainbow_r, seismic, seismic_r, spring, spring_r, summer, summer_r, tab10, tab10_r, tab20, tab20_r, tab20b, tab20b_r, tab20c, tab20c_r, terrain, terrain_r, viridis, viridis_r, winter, winter_r",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-177-947ca519f9a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'color'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs)\u001b[0m\n\u001b[0;32m   3203\u001b[0m                         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3204\u001b[0m                         \u001b[0mimlim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3205\u001b[1;33m                         **kwargs)\n\u001b[0m\u001b[0;32m   3206\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3207\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1853\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1855\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1856\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5483\u001b[0m         im = mimage.AxesImage(self, cmap, norm, interpolation, origin, extent,\n\u001b[0;32m   5484\u001b[0m                               \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5485\u001b[1;33m                               resample=resample, **kwargs)\n\u001b[0m\u001b[0;32m   5486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5487\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, ax, cmap, norm, interpolation, origin, extent, filternorm, filterrad, resample, **kwargs)\u001b[0m\n\u001b[0;32m    822\u001b[0m             \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    823\u001b[0m             \u001b[0mresample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 824\u001b[1;33m             \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    825\u001b[0m         )\n\u001b[0;32m    826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, ax, cmap, norm, interpolation, origin, filternorm, filterrad, resample, **kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \"\"\"\n\u001b[0;32m    227\u001b[0m         \u001b[0mmartist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mArtist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         \u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mScalarMappable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mouseover\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0morigin\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\cm.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, norm, cmap)\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;31m#: The Colormap instance of this ScalarMappable.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_cmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m         \u001b[1;31m#: The last colorbar associated with this ScalarMappable. May be None.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolorbar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\cm.py\u001b[0m in \u001b[0;36mget_cmap\u001b[1;34m(name, lut)\u001b[0m\n\u001b[0;32m    166\u001b[0m         raise ValueError(\n\u001b[0;32m    167\u001b[0m             \u001b[1;34m\"Colormap %s is not recognized. Possible values are: %s\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m             % (name, ', '.join(sorted(cmap_d))))\n\u001b[0m\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Colormap color is not recognized. Possible values are: Accent, Accent_r, Blues, Blues_r, BrBG, BrBG_r, BuGn, BuGn_r, BuPu, BuPu_r, CMRmap, CMRmap_r, Dark2, Dark2_r, GnBu, GnBu_r, Greens, Greens_r, Greys, Greys_r, OrRd, OrRd_r, Oranges, Oranges_r, PRGn, PRGn_r, Paired, Paired_r, Pastel1, Pastel1_r, Pastel2, Pastel2_r, PiYG, PiYG_r, PuBu, PuBuGn, PuBuGn_r, PuBu_r, PuOr, PuOr_r, PuRd, PuRd_r, Purples, Purples_r, RdBu, RdBu_r, RdGy, RdGy_r, RdPu, RdPu_r, RdYlBu, RdYlBu_r, RdYlGn, RdYlGn_r, Reds, Reds_r, Set1, Set1_r, Set2, Set2_r, Set3, Set3_r, Spectral, Spectral_r, Wistia, Wistia_r, YlGn, YlGnBu, YlGnBu_r, YlGn_r, YlOrBr, YlOrBr_r, YlOrRd, YlOrRd_r, afmhot, afmhot_r, autumn, autumn_r, binary, binary_r, bone, bone_r, brg, brg_r, bwr, bwr_r, cividis, cividis_r, cool, cool_r, coolwarm, coolwarm_r, copper, copper_r, cubehelix, cubehelix_r, flag, flag_r, gist_earth, gist_earth_r, gist_gray, gist_gray_r, gist_heat, gist_heat_r, gist_ncar, gist_ncar_r, gist_rainbow, gist_rainbow_r, gist_stern, gist_stern_r, gist_yarg, gist_yarg_r, gnuplot, gnuplot2, gnuplot2_r, gnuplot_r, gray, gray_r, hot, hot_r, hsv, hsv_r, inferno, inferno_r, jet, jet_r, magma, magma_r, nipy_spectral, nipy_spectral_r, ocean, ocean_r, pink, pink_r, plasma, plasma_r, prism, prism_r, rainbow, rainbow_r, seismic, seismic_r, spring, spring_r, summer, summer_r, tab10, tab10_r, tab20, tab20_r, tab20b, tab20b_r, tab20c, tab20c_r, terrain, terrain_r, viridis, viridis_r, winter, winter_r"
     ]
    }
   ],
   "source": [
    "test_image = next(test_set)\n",
    "plt.imshow(test_image[0][0][:,:,:],cmap='color')\n",
    "plt.show()\n",
    "np.argmax(model.predict(test_image[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cap = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
